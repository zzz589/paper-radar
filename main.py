import requests
import os
from datetime import datetime
import math

# === é…ç½®é¡¹ ===
KEYWORDS = os.environ.get("KEYWORDS", "Large Language Models") 
# æ—¶é—´çª—ï¼š6 - 12 ä¸ªæœˆ
MIN_MONTHS = 6  
MAX_MONTHS = 13 # ç¨å¾®æ”¾å®½ä¸€ç‚¹ä¸Šé™ï¼Œé˜²æ­¢å› ä¸ºåˆšå¥½è¿‡äº†ä¸€å¹´è¢«åˆ‡æ‰
# åŸºç¡€é—¨æ§›ï¼šé™ä½åˆ° 1ï¼Œç¡®ä¿è‡³å°‘èƒ½æŠ“åˆ°ä¸œè¥¿ï¼Œå“ªæ€•æ˜¯åˆšèµ·æ­¥çš„
MIN_CITATIONS = 1 

def fetch_and_analyze():
    print(f"ğŸ” æ­£åœ¨æ£€ç´¢å…³é”®è¯: {KEYWORDS}...")
    
    current_year = datetime.now().year
    # æ‰©å¤§æ£€ç´¢èŒƒå›´ï¼Œç¡®ä¿ä¸æ¼æ‰
    year_range = f"{current_year-2}-{current_year}"
    
    url = "https://api.semanticscholar.org/graph/v1/paper/search"
    params = {
        "query": KEYWORDS,
        "year": year_range,
        "limit": 100,
        # ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šæŒ‰å¼•ç”¨é‡é™åºè·å–ï¼Œè€Œä¸æ˜¯æŒ‰ç›¸å…³æ€§
        # è¿™æ ·èƒ½ä¿è¯å–å›æ¥çš„éƒ½æ˜¯å¼•ç”¨é«˜çš„ï¼Œè€Œä¸æ˜¯åˆšå‘çš„
        "sort": "citationCount:desc", 
        "fields": "title,publicationDate,citationCount,influentialCitationCount,abstract,url,authors"
    }
    
    try:
        response = requests.get(url, params=params, timeout=10)
        data = response.json().get('data', [])
        print(f"ğŸ“¡ API è¿”å›äº† {len(data)} ç¯‡åŸå§‹è®ºæ–‡ï¼Œæ­£åœ¨è¿›è¡Œæ—¶é—´çª—è¿‡æ»¤...")
    except Exception as e:
        print(f"API Error: {e}")
        return []

    candidates = []
    current_date = datetime.now()

    for paper in data:
        # æ•°æ®æ¸…æ´—ï¼šæ²¡æœ‰æ—¥æœŸçš„è·³è¿‡
        if not paper.get('publicationDate'): continue
        
        try:
            pub_date = datetime.strptime(paper['publicationDate'], "%Y-%m-%d")
        except:
            continue
            
        days_diff = (current_date - pub_date).days
        months_diff = days_diff / 30.0
        
        # è°ƒè¯•ä¿¡æ¯ï¼šä½ å¯ä»¥çœ‹åˆ°è„šæœ¬å®é™…ä¸Šåœ¨çœ‹å“ªäº›è®ºæ–‡ï¼ˆåªåœ¨Logé‡Œæ˜¾ç¤ºï¼‰
        # print(f"Checking: {paper['title'][:30]}... ({months_diff:.1f} months ago, {paper['citationCount']} cites)")

        # Step 1: æ—¶é—´çª—ç­›é€‰ (6-13ä¸ªæœˆ)
        if not (MIN_MONTHS <= months_diff <= MAX_MONTHS):
            continue
            
        # Step 2: åŸºç¡€è¿‡æ»¤ (å¼•ç”¨æ•° >= 1)
        if paper['citationCount'] < MIN_CITATIONS:
            continue
            
        # Step 3: è®¡ç®—åŠ é€Ÿåº¦
        velocity = paper['citationCount'] / months_diff
        
        # åŠ æƒåˆ†
        score = velocity + (paper['influentialCitationCount'] * 2)

        candidates.append({
            "title": paper['title'],
            "date": paper['publicationDate'],
            "months_ago": round(months_diff, 1),
            "citations": paper['citationCount'],
            "influential": paper['influentialCitationCount'],
            "velocity": round(velocity, 2),
            "score": score,
            "url": paper['url'],
            "abstract": paper.get('abstract', 'No abstract')
        })

    # æŒ‰åˆ†æ•°æ’åº
    candidates.sort(key=lambda x: x['score'], reverse=True)
    print(f"âœ… ç­›é€‰åå‰©ä½™ {len(candidates)} ç¯‡ç¬¦åˆæ¡ä»¶çš„è®ºæ–‡")
    return candidates[:10]

def generate_report(papers):
    # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œç”Ÿæˆä¸€ä¸ªå¸¦æœ‰è°ƒè¯•ä¿¡æ¯çš„ç©ºæŠ¥å‘Š
    if not papers:
        return (f"# âš ï¸ æœ¬å‘¨æœªå‘ç°ç¬¦åˆæ ‡å‡†çš„è®ºæ–‡\n\n"
                f"**å½“å‰è®¾ç½®**:\n"
                f"- å…³é”®è¯: `{KEYWORDS}`\n"
                f"- æ—¶é—´çª—: {MIN_MONTHS}-{MAX_MONTHS} ä¸ªæœˆå‰\n"
                f"- æœ€ä½å¼•ç”¨: {MIN_CITATIONS}\n\n"
                f"**å¯èƒ½åŸå› **: è¯¥é¢†åŸŸåœ¨æŒ‡å®šæ—¶é—´æ®µå†…ï¼ˆçº¦ä¸€å¹´å‰ï¼‰æ²¡æœ‰é«˜å¼•ç”¨çˆ†å‘çš„è®ºæ–‡ï¼Œæˆ–è€…APIæœªèƒ½è·å–åˆ°æ•°æ®ã€‚\n"
                f"å»ºè®®ï¼šå°è¯•åœ¨ main.py ä¸­å°† MIN_MONTHS æ”¹ä¸º 3ï¼Œæˆ–æ›´æ¢å…³é”®è¯æµ‹è¯•ã€‚")
    
    md = f"# ğŸš€ æ¯å‘¨é«˜æ½œåŠ›è®ºæ–‡æŒ–æ˜ ({datetime.now().strftime('%Y-%m-%d')})\n"
    md += f"**å…³é”®è¯**: `{KEYWORDS}` | **ç­›é€‰æ ‡å‡†**: å‘å¸ƒäº {MIN_MONTHS}-{MAX_MONTHS} ä¸ªæœˆå‰ | æŒ‰å¼•ç”¨åŠ é€Ÿåº¦æ’åº\n\n"
    
    for i, p in enumerate(papers):
        md += f"### {i+1}. [{p['title']}]({p['url']})\n"
        md += f"- **ğŸ”¥ å¼•ç”¨åŠ é€Ÿåº¦**: `{p['velocity']} æ¬¡/æœˆ`\n"
        md += f"- **ğŸ“ˆ æ€»å¼•ç”¨**: {p['citations']} | **ğŸŒŸ æ ¸å¿ƒå¼•ç”¨**: {p['influential']}\n"
        md += f"- **ğŸ“… å‘å¸ƒæ—¶é—´**: {p['date']} (çº¦ {p['months_ago']} ä¸ªæœˆå‰)\n"
        md += "<details><summary>ğŸ“– ç‚¹å‡»å±•å¼€æ‘˜è¦</summary>\n\n"
        md += f"{p['abstract']}\n"
        md += "\n</details>\n\n"
        md += "---\n"
    
    return md

if __name__ == "__main__":
    top_papers = fetch_and_analyze()
    report = generate_report(top_papers)
    with open("report.md", "w", encoding="utf-8") as f:
        f.write(report)
    print("æŠ¥å‘Šå·²ç”Ÿæˆã€‚")
