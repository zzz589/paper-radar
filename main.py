import requests
import os
from datetime import datetime
import math

# === é…ç½®é¡¹ ===
# ä½ å¯ä»¥åœ¨ GitHub Secrets è®¾ç½® KEYWORDSï¼Œä¹Ÿå¯ä»¥ç›´æ¥åœ¨è¿™é‡Œæ”¹
KEYWORDS = os.environ.get("KEYWORDS", "Large Language Models") 
# åªçœ‹å‘å¸ƒäº† 6 - 12 ä¸ªæœˆçš„
MIN_MONTHS = 6  
MAX_MONTHS = 12
# åŸºç¡€é—¨æ§›ï¼šæ¯”å¦‚è¿™æœŸé—´è‡³å°‘è¦æœ‰ 5 ä¸ªå¼•ç”¨
MIN_CITATIONS = 5

def fetch_and_analyze():
    print(f"ğŸ” æ­£åœ¨æ£€ç´¢å…³é”®è¯: {KEYWORDS}...")
    
    # åŠ¨æ€è®¡ç®—å¹´ä»½èŒƒå›´ï¼ˆè¿‘ä¸¤å¹´ï¼‰
    current_year = datetime.now().year
    year_range = f"{current_year-2}-{current_year}"
    
    url = "https://api.semanticscholar.org/graph/v1/paper/search"
    params = {
        "query": KEYWORDS,
        "year": year_range,
        "limit": 100, # æ¯æ¬¡åˆ†æå‰100ä¸ªç›¸å…³åº¦æœ€é«˜çš„
        "fields": "title,publicationDate,citationCount,influentialCitationCount,abstract,url,authors"
    }
    
    try:
        response = requests.get(url, params=params, timeout=10)
        data = response.json().get('data', [])
    except Exception as e:
        print(f"API Error: {e}")
        return []

    candidates = []
    current_date = datetime.now()

    for paper in data:
        if not paper.get('publicationDate'): continue
        
        # --- æ ¸å¿ƒé€»è¾‘ï¼šæ—¶é—´çª—ç­›é€‰ ---
        try:
            pub_date = datetime.strptime(paper['publicationDate'], "%Y-%m-%d")
        except:
            continue
            
        days_diff = (current_date - pub_date).days
        months_diff = days_diff / 30.0
        
        # Step 1: å¿…é¡»æ˜¯ 6-12 ä¸ªæœˆå‰çš„
        if not (MIN_MONTHS <= months_diff <= MAX_MONTHS):
            continue
            
        # Step 2: åŸºç¡€è¿‡æ»¤
        if paper['citationCount'] < MIN_CITATIONS:
            continue
            
        # --- Step 3: å¸®ä½ è‡ªåŠ¨è®¡ç®— citation acceleration ---
        # é€Ÿåº¦ = æ€»å¼•ç”¨ / å‘å¸ƒæœˆæ•°
        velocity = paper['citationCount'] / months_diff
        
        # åŠ æƒåˆ†ï¼šé«˜å½±å“åŠ›å¼•ç”¨æƒé‡ x 2
        score = velocity + (paper['influentialCitationCount'] * 2)

        candidates.append({
            "title": paper['title'],
            "date": paper['publicationDate'],
            "months_ago": round(months_diff, 1),
            "citations": paper['citationCount'],
            "influential": paper['influentialCitationCount'],
            "velocity": round(velocity, 2),
            "score": score,
            "url": paper['url'],
            "abstract": paper.get('abstract', 'No abstract')
        })

    # æŒ‰è®¡ç®—å‡ºçš„â€œåŠ é€Ÿåº¦å¾—åˆ†â€æ’åº
    candidates.sort(key=lambda x: x['score'], reverse=True)
    return candidates[:10] # åªå–å‰10å

def generate_report(papers):
    if not papers:
        return "æœ¬å‘¨æ²¡æœ‰å‘ç°ç¬¦åˆç­›é€‰æ ‡å‡†ï¼ˆ6-12ä¸ªæœˆå‰ + é«˜å¼•ç”¨å¢é•¿ï¼‰çš„è®ºæ–‡ã€‚"
    
    md = f"# ğŸš€ æ¯å‘¨é«˜æ½œåŠ›è®ºæ–‡æŒ–æ˜ ({datetime.now().strftime('%Y-%m-%d')})\n"
    md += f"**å…³é”®è¯**: `{KEYWORDS}` | **ç­›é€‰æ ‡å‡†**: å‘å¸ƒäº {MIN_MONTHS}-{MAX_MONTHS} ä¸ªæœˆå‰ | æŒ‰å¼•ç”¨åŠ é€Ÿåº¦æ’åº\n\n"
    
    for i, p in enumerate(papers):
        # æ ‡é¢˜è¡Œ
        md += f"### {i+1}. [{p['title']}]({p['url']})\n"
        
        # å…³é”®æŒ‡æ ‡å±•ç¤º
        md += f"- **ğŸ”¥ å¼•ç”¨åŠ é€Ÿåº¦**: `{p['velocity']} æ¬¡/æœˆ`\n"
        md += f"- **ğŸ“ˆ æ€»å¼•ç”¨**: {p['citations']} | **ğŸŒŸ æ ¸å¿ƒå¼•ç”¨**: {p['influential']}\n"
        md += f"- **ğŸ“… å‘å¸ƒæ—¶é—´**: {p['date']} (çº¦ {p['months_ago']} ä¸ªæœˆå‰)\n"
        
        # æ‘˜è¦ï¼ˆæŠ˜å æ˜¾ç¤ºï¼Œä¿æŒé¡µé¢æ•´æ´ï¼‰
        md += "<details><summary>ğŸ“– ç‚¹å‡»å±•å¼€æ‘˜è¦</summary>\n\n"
        md += f"{p['abstract']}\n"
        md += "\n</details>\n\n"
        md += "---\n"
    
    return md

if __name__ == "__main__":
    top_papers = fetch_and_analyze()
    report = generate_report(top_papers)
    
    # å°†ç»“æœå†™å…¥ç¯å¢ƒå˜é‡ï¼Œä¾› GitHub Action è°ƒç”¨
    # æ³¨æ„ï¼šåœ¨ Action ä¸­å¦‚æœå†…å®¹å¤ªé•¿ï¼Œéœ€è¦ç”¨ç‰¹æ®Šæ–¹å¼å†™å…¥ GITHUB_OUTPUTï¼Œè¿™é‡Œç›´æ¥å†™å…¥æ–‡ä»¶æ›´ç¨³å¦¥
    with open("report.md", "w", encoding="utf-8") as f:
        f.write(report)
    print("æŠ¥å‘Šå·²ç”Ÿæˆã€‚")
